version: '3'

services:
  app: &app
    image: "${CI_REGISTRY_IMAGE:-registry.gitlab.com/flotechnologies/app}:latest"
    build:
      context: .
      dockerfile: Dockerfile.run

      args:
        BINTRAY_USER: "${BINTRAY_USER}"
        BINTRAY_KEY: "${BINTRAY_KEY}"
        MAVEN_MIRROR: "${MAVEN_MIRROR}"
        CI_COMMIT_SHA: "${CI_COMMIT_SHA:-none}"
        CI_COMMIT_MESSAGE: "${CI_COMMIT_MESSAGE:-none of foo bar}"
        COMMIT_TIME: "${COMMIT_TIME:-none}"

    volumes:
      - ./creds:/app/creds
      - "${HOME}/.sbt:/root/.sbt"
  # This is used to automatically tag the image with CI_PIPELINE_ID
  app-tag:
    entrypoint: "true"
    image: "${CI_REGISTRY_IMAGE:-registry.gitlab.com/flotechnologies/app}:${CI_PIPELINE_ID:-latest}"
    ports: []
    <<: *app

  kubectl-config:
    image: artemz/helm-kubectl
    environment:
      K8S_URL: "${K8S_URL}"
      K8S_TOKEN: "${K8S_TOKEN}"
    entrypoint: /scripts/kubectl-setup-entrypoint.sh
    volumes:
      - ./kubeconfig:/root/.kube
      - ./deployment/scripts:/scripts/

  eks-kubectl-config:
    image: atlassian/pipelines-awscli
    environment:
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID:-empty}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY:-empty}"
      AWS_DEFAULT_REGION: "us-west-2"
    entrypoint: |
      aws eks --region us-west-2 update-kubeconfig --name gitlab-runners
    volumes:
      - ./kubeconfig:/root/.kube

  eks-deploy:
    image: artemz/helm-kubectl
    environment:
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID:-empty}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY:-empty}"
      AWS_DEFAULT_REGION: "us-west-2"
    entrypoint: |
      helm upgrade --install dev --namespace services /root/deployment
    volumes:
      - ./kubeconfig:/root/.kube
      - ./deployment:/root/deployment

networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1440

