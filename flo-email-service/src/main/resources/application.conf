akka.http {
  server {
    pipelining-limit = 32
  }

  host-connection-pool {
    max-connections = 2048
    min-connections = 0
    max-retries = 5
    max-open-requests = 1024
    pipelining-limit = 32
  }
}

kafka {
  host = ${?KAFKA_HOST}
  group-id = ${?KAFKA_GROUP_ID}
  topic = ${?KAFKA_TOPIC}
  topic-v2 = ${?KAFKA_TOPIC_V2}
  topic-v3 = ${?KAFKA_TOPIC_V3}

  consumer-name = "email-sender"
  filter-time-in-seconds = ${?KAFKA_FILTER_TIME_IN_SECONDS}
  poll-timeout = ${?KAFKA_CONSUMER_POLL_TIMEOUT}
  max-poll-records = ${?KAFKA_CONSUMER_MAX_POLL_RECORDS}
  encryption = ${?KAFKA_ENCRYPTION_ENABLED}
}

send-with-us {
  api-key = ${?SEND_WITH_US_API_KEY}
  default-email-address = ${?SEND_WITH_US_DEFAULT_EMAIL_ADDRESS}
  reply-to-email-address = ${?SEND_WITH_US_REPLY_TO_EMAIL_ADDRESS}
}

flo {
  api {
    url = ${?FLO_API_URL}
    user = ${?FLO_API_USER}
    token = ${?FLO_API_TOKEN}
  }
}

email-templates {
  alarm-severity-low = ${?EMAIL_TEMPLATE_ALARM_SEVERITY_LOW}
  alarm-severity-medium = ${?EMAIL_TEMPLATE_ALARM_SEVERITY_MEDIUM}
  alarm-severity-high = ${?EMAIL_TEMPLATE_ALARM_SEVERITY_HIGH}
}

cipher {
  key-provider {
    bucket-region = ${?KEY_PROVIDER_BUCKET_REGION}
    bucket-name = ${?KEY_PROVIDER_BUCKET_NAME}
    key-path-template = ${?KEY_PROVIDER_KEY_PATH_TEMPLATE}
    key-id = ${?KEY_ID}
  }
}

# Kamon configuration
kamon {
  system-metrics {
    sigar-enabled = false
    jmx-enabled = false
  }

  metric {
    filters {
      akka-actor {
        includes = [  ]
        excludes = [ "*/system/**", "*/user/IO-**", "*kamon*", "*/kamon/*", "**/kamon/**", "kamon/**" ]
      }

      akka-router {
        includes = [  ]
        excludes = [ "*/system/**", "*/user/IO-**", "*kamon*", "*/kamon/*", "**/kamon/**", "kamon/**" ]
      }

      akka-dispatcher {
        includes = [  ]
        excludes = [ "*/system/**", "*/user/IO-**", "*kamon*", "*/kamon/*", "**/kamon/**", "kamon/**" ]
      }

      trace {
        includes = [ "**" ]
        excludes = [ ]
      }

      http {
        includes = [ "**" ]
        excludes = [ ]
      }
    }
  }

  statsd {

    report-system-metrics = false

    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
    hostname = ${?STATSD_HOST}
    port = ${?STATSD_PORT}

    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
    # kamon.metric.tick-interval setting.
    # flush-interval = 10 seconds

    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
    subscriptions {
      histogram       = [ "**" ]
      min-max-counter = [ "**" ]
      gauge           = [ "**" ]
      counter         = [ "**" ]
      trace           = [ "**" ]
      trace-segment   = [ "**" ]
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
      system-metric   = [ "**" ]
      http-server     = [ "**" ]
      http = [ "**" ]
      kafka-consumer = [ "**" ]
    }

    # FQCN of the implementation of `kamon.statsd.MetricKeyGenerator` to be instantiated and used for assigning
    # metric names. The implementation must have a single parameter constructor accepting a `com.typesafe.config.Config`.
    metric-key-generator = kamon.statsd.SimpleMetricKeyGenerator

    simple-metric-key-generator {

      # The default namespacing scheme for metrics follows
      # this pattern:
      #    application.host.entity.entity-name.metric-name
      application = "kamon"

      include-hostname = false

      # When the sections that make up the metric names have special characters like dots (very common in dispatcher
      # names) or forward slashes (all actor metrics) we need to sanitize those values before sending them to StatsD
      # with one of the following strategies:
      #   - normalize: changes ': ' to '-' and ' ', '/' and '.' to '_'.
      #   - percent-encode: percent encode the section on the metric name. Please note that StatsD doesn't support
      #     percent encoded metric names, this option is only useful if using our docker image which has a patched
      #     version of StatsD or if you are running your own, customized version of StatsD that supports this.
      metric-name-normalization-strategy = normalize
    }
  }
}
